{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5497796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib.pyplot import pie, axis, show\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.regression.linear_model as sm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, CompoundKernel\n",
    "import sklearn_relief as sr\n",
    "from skrebate import ReliefF\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import lightgbm as ltb\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import ks_2samp\n",
    "from tabulate import tabulate\n",
    "\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "from sklearn.multioutput import RegressorChain, MultiOutputRegressor\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from helper import preprocess, countUsers, get_features_relieff, get_features_ref_single, get_features_ref,\\\n",
    "    get_features_kbest, outlier_detect, cross_val, get_scores\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3c427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/X_train.csv', sep = ',',decimal = '.', encoding = 'utf-8', engine ='python', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10041ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read common variables from a YAML file\n",
    "with open('../../common_variables.yaml', 'r') as file:\n",
    "    common_data = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a571b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data : (2660, 125)\n",
      "Shape of data after excluding missing response: (2331, 125)\n",
      "Shape of full data after selecting date range dates > 21 days (1752, 116)\n"
     ]
    }
   ],
   "source": [
    "target_variable = 'hba1c_12m'\n",
    "df, X_train, X_test, Y_train, Y_test, X, Y, scaler, df_missing_val, df_missing_val_original, df_original = preprocess(df, 0.25, target_variable)\n",
    "df = df.drop(['ldl_12m', 'bmi_12m', 'hdl_12m'], axis=1)\n",
    "X_train = X_train.drop(['ldl_12m', 'bmi_12m', 'hdl_12m'], axis=1)\n",
    "X_test = X_test.drop(['ldl_12m', 'bmi_12m', 'hdl_12m'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127de595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>init_year</th>\n",
       "      <th>drug_class</th>\n",
       "      <th>MD_RCT_mmol_mol</th>\n",
       "      <th>hba1c_bl_18m</th>\n",
       "      <th>hba1c_bl_6m</th>\n",
       "      <th>sp</th>\n",
       "      <th>ika</th>\n",
       "      <th>t2d_dur_y</th>\n",
       "      <th>P_Krea</th>\n",
       "      <th>...</th>\n",
       "      <th>dg132</th>\n",
       "      <th>dg133</th>\n",
       "      <th>n_of_dis</th>\n",
       "      <th>days_hba1c</th>\n",
       "      <th>days_bmi</th>\n",
       "      <th>days_hdl</th>\n",
       "      <th>days_ldl</th>\n",
       "      <th>ldl_12m</th>\n",
       "      <th>hdl_12m</th>\n",
       "      <th>bmi_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960794</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.107438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152629</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.14585</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8656</th>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.411912</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152629</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.14585</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>0.002162</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823574</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289440</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.14585</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12113</th>\n",
       "      <td>0.009255</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882382</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122274</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.14585</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823574</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152629</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.14585</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7848</th>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823574</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105173</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.14585</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>0.004768</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960794</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.334711</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.147926</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.14585</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.177686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152629</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.14585</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.276860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.213339</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.14585</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960794</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.376033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152629</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.14585</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  init_year  drug_class  MD_RCT_mmol_mol  hba1c_bl_18m  \\\n",
       "6673   0.005106      0.000         0.0         0.960794      0.161905   \n",
       "8656   0.006635      0.875         1.0         0.411912      0.161905   \n",
       "2857   0.002162      1.000         0.0         0.823574      0.161905   \n",
       "12113  0.009255      0.875         1.0         0.882382      0.276190   \n",
       "6305   0.004845      0.375         0.0         0.823574      0.123810   \n",
       "...         ...        ...         ...              ...           ...   \n",
       "7848   0.006048      0.875         0.0         0.823574      0.161905   \n",
       "6216   0.004768      1.000         0.0         0.960794      0.257143   \n",
       "8133   0.006267      1.000         1.0         1.000000      0.190476   \n",
       "6160   0.004716      0.875         1.0         1.000000      0.285714   \n",
       "279    0.000194      0.625         0.0         0.960794      0.161905   \n",
       "\n",
       "       hba1c_bl_6m   sp       ika  t2d_dur_y    P_Krea  ...  dg132  dg133  \\\n",
       "6673      0.171875  1.0  0.500000   0.095238  0.107438  ...    0.0    0.0   \n",
       "8656      0.046875  1.0  0.474359   0.119048  0.123967  ...    0.0    0.0   \n",
       "2857      0.375000  0.0  0.512821   0.166667  0.061983  ...    0.0    0.0   \n",
       "12113     0.046875  1.0  0.397436   0.166667  0.165289  ...    0.0    0.0   \n",
       "6305      0.046875  0.0  0.794872   0.285714  0.173554  ...    0.0    0.0   \n",
       "...            ...  ...       ...        ...       ...  ...    ...    ...   \n",
       "7848      0.171875  0.0  0.974359   0.000000  0.206612  ...    0.0    0.0   \n",
       "6216      0.343750  1.0  0.769231   0.261905  0.334711  ...    1.0    0.0   \n",
       "8133      0.000000  1.0  0.679487   0.142857  0.177686  ...    0.0    0.0   \n",
       "6160      0.484375  1.0  0.538462   0.238095  0.276860  ...    0.0    0.0   \n",
       "279       0.234375  0.0  0.423077   0.071429  0.376033  ...    0.0    0.0   \n",
       "\n",
       "       n_of_dis  days_hba1c  days_bmi  days_hdl  days_ldl   ldl_12m   hdl_12m  \\\n",
       "6673   0.071429         1.0  0.152629  0.102099   0.14585  0.296296  0.228571   \n",
       "8656   0.214286         1.0  0.152629  0.102099   0.14585  0.296296  0.228571   \n",
       "2857   0.500000         1.0  0.289440  0.102099   0.14585  0.296296  0.228571   \n",
       "12113  0.214286         1.0  0.122274  0.102099   0.14585  0.296296  0.228571   \n",
       "6305   0.214286         1.0  0.152629  0.102099   0.14585  0.296296  0.228571   \n",
       "...         ...         ...       ...       ...       ...       ...       ...   \n",
       "7848   0.285714         1.0  0.105173  0.102099   0.14585  0.296296  0.228571   \n",
       "6216   0.428571         1.0  0.147926  0.102099   0.14585  0.296296  0.228571   \n",
       "8133   0.428571         1.0  0.152629  0.102099   0.14585  0.296296  0.228571   \n",
       "6160   0.142857         1.0  1.213339  0.102099   0.14585  0.296296  0.228571   \n",
       "279    0.214286         1.0  0.152629  0.102099   0.14585  0.296296  0.228571   \n",
       "\n",
       "        bmi_12m  \n",
       "6673   0.000245  \n",
       "8656   0.000245  \n",
       "2857   0.000152  \n",
       "12113  0.000571  \n",
       "6305   0.000245  \n",
       "...         ...  \n",
       "7848   0.000271  \n",
       "6216   0.000215  \n",
       "8133   0.000245  \n",
       "6160   0.000216  \n",
       "279    0.000245  \n",
       "\n",
       "[329 rows x 115 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f0bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train with whole dataset and test with drug class 2,3 and 4 data\n",
    "is_train_with_all=False\n",
    "if(is_train_with_all):\n",
    "    combined_df = pd.concat([X_test, Y_test], axis=1)\n",
    "    testdf = combined_df[(combined_df['drug_class'] == 0.25) | \n",
    "                         (combined_df['drug_class'] == 0.375) ]\n",
    "    X_test = testdf.drop([response_variable], axis = 1)\n",
    "    Y_test = testdf[response_variable]\n",
    "    \n",
    "X_test_original = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3868653f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== sample count in preprocessed data =======\n",
      " number of dpp4 :  679\n",
      " number of sglt2 :  1073\n",
      "==== sample count in training data =======\n",
      " number of dpp4 :  516\n",
      " number of sglt2 :  798\n",
      "==== sample count in testing data =======\n",
      " number of dpp4 :  163\n",
      " number of sglt2 :  275\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Use drug_class\n",
    "\n",
    "2=GLP-1 analogues (A10BJ)\n",
    "3=DPP-4 inhibitors (A10BH)\n",
    "4=SGLT2 inhibitors (A10BK)\n",
    "\"\"\"\n",
    "\n",
    "if(is_train_with_all):\n",
    "    sglt_val = 0.375\n",
    "    dpp_val = 0.25\n",
    "else:\n",
    "    sglt_val = 1\n",
    "    dpp_val = 0\n",
    "\n",
    "\n",
    "X_test_ = pd.DataFrame(X_test)\n",
    "X_train_ = pd.DataFrame(X_train)\n",
    "\n",
    "X_train = X_train.drop(['init_year'], axis = 1)\n",
    "X_test = X_test.drop(['init_year'], axis = 1)\n",
    "\n",
    "\n",
    "print('==== sample count in preprocessed data =======')\n",
    "print(' number of dpp4 : ', countUsers(3, df))\n",
    "print(' number of sglt2 : ', countUsers(4, df))\n",
    "\n",
    "print('==== sample count in training data =======')\n",
    "print(' number of dpp4 : ', countUsers(dpp_val, X_train_))\n",
    "print(' number of sglt2 : ', countUsers(sglt_val, X_train_))\n",
    "\n",
    "print('==== sample count in testing data =======')\n",
    "print(' number of dpp4 : ', countUsers(dpp_val, X_test_))\n",
    "print(' number of sglt2 : ', countUsers(sglt_val, X_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da26053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hba1c_bl_6m', 'insulin', 'hba1c_bl_18m', 'sum_diab_drugs', 'MD_RCT_mmol_mol', 'drug_class', 'dpp4', 't2d_dur_y', 'gluk', 'concordant_dis', 'met_oad0', 'trigly', 'hyperten', 'ika']\n"
     ]
    }
   ],
   "source": [
    "# TODO FROM HERE\n",
    "\n",
    "# feature selection\n",
    "items = [\n",
    "#     'sp',\n",
    "#     'smoking',\n",
    "    ]\n",
    "k = 10 # Select top 25 features\n",
    "    \n",
    "random.seed(42)\n",
    "\n",
    "#feats = get_features_ref_single(X_train, Y_train,20)\n",
    "#feats = get_features_relieff(X_train, Y_train['hba1c_12m'] ,15)\n",
    "#feats = get_features_kbest(X_train, Y_train,10)\n",
    "\n",
    "# feats got from reliefF with 15\n",
    "feats = ['hba1c_bl_6m', 'insulin', 'hba1c_bl_18m', 'sum_diab_drugs', 'MD_RCT_mmol_mol', 'drug_class', 'dpp4', 't2d_dur_y', 'gluk', 'concordant_dis', 'met_oad0', 'trigly', 'hyperten', 'ika']\n",
    "print(feats)\n",
    "selected_features=feats\n",
    "        \n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "number_of_features = len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da5a5fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data before removing outliers: (1314, 14)\n",
      "Shape of test data before removing outliers: (438, 14)\n",
      "Training set outliers: [340, 3662, 3693, 6014, 11741]\n",
      "Testing set outliers: [11564]\n",
      "Shape of training data after removing outliers: (1309, 14)\n",
      "Shape of test data after removing outliers: (437, 14)\n"
     ]
    }
   ],
   "source": [
    "################# OUTLIER CODE ################\n",
    "print('Shape of training data before removing outliers:', np.shape(X_train))\n",
    "print('Shape of test data before removing outliers:', np.shape(X_test))\n",
    "    \n",
    "out_train, out_test = outlier_detect(X_train, Y_train, X_test, Y_test)\n",
    "response_variable_list = [target_variable]\n",
    "\n",
    "train_ = X_train.copy()\n",
    "train_[response_variable_list] = Y_train.values\n",
    "    \n",
    "test_ = X_test.copy()\n",
    "test_[response_variable_list] = Y_test.values\n",
    "    \n",
    "train_ = pd.DataFrame(train_.drop(out_train, axis = 0))\n",
    "test_ = pd.DataFrame(test_.drop(out_test, axis = 0))\n",
    "    \n",
    "Y_train = train_[response_variable_list]\n",
    "X_train = train_.drop(response_variable_list, axis=1)\n",
    "    \n",
    "Y_test = test_[response_variable_list]\n",
    "X_test = test_.drop(response_variable_list, axis=1)\n",
    "    \n",
    "print('Shape of training data after removing outliers:', np.shape(X_train))\n",
    "print('Shape of test data after removing outliers:', np.shape(X_test))\n",
    "\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7669d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train.copy()\n",
    "train[response_variable_list] = Y_train[response_variable_list].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c5464",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "239e36c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/anushaihalapathirana/anaconda3/envs/EUF/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation variance 0.0034985521156825497\n",
      "Cross validation mean score 0.41095921946435865\n",
      "50.16428910131443\n",
      "R2 score Training : 0.4533285725815641\n",
      "R2 score Testing : 0.4009036844768954\n",
      "RMSE (Target): 9.13239691384006\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(\n",
    "    n_estimators=20, \n",
    "    eta=0.001, \n",
    "    subsample=0.2, \n",
    "    colsample_bytree=0.8,\n",
    "    alpha=0.1,\n",
    "    max_depth = 15,\n",
    "    max_leaves = 10,\n",
    "    learning_rate =0.1\n",
    ")\n",
    "\n",
    "#model = CatBoostRegressor(iterations=20,learning_rate=0.1, depth=6)\n",
    "\n",
    "#model = RandomForestRegressor(n_estimators=150, max_depth=10, random_state=123)\n",
    "model = MLPRegressor(random_state=123, max_iter=2000,hidden_layer_sizes = 16,learning_rate= 'adaptive')\n",
    "\n",
    "model = cross_val(model, train , X_train, Y_train, response_variable_list)\n",
    "model.fit(X_train, Y_train)\n",
    "# make a prediction\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "# summarize prediction\n",
    "print(yhat[1])\n",
    "original_data_pred, model_results, model_results_drugs_ori, score_ori = get_scores(model, X_test, Y_test, X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c9a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_missing_val = df_missing_val[selected_features]\n",
    "mv_pred_test_numpy = model.predict(df_missing_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3cb8e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mv_pred_test_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b549e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_val_original['hba1c_12m'] = mv_pred_test_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49bccafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6673     53.334371\n",
       "8656     45.124345\n",
       "2857     62.081110\n",
       "12113    53.281130\n",
       "6305     50.841591\n",
       "           ...    \n",
       "7848     56.294547\n",
       "6216     65.749411\n",
       "8133     52.081039\n",
       "6160     66.333191\n",
       "279      57.573497\n",
       "Name: hba1c_12m, Length: 329, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing_val_original['hba1c_12m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22fbb9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>init_year</th>\n",
       "      <th>drug_class</th>\n",
       "      <th>MD_RCT_mmol_mol</th>\n",
       "      <th>hba1c_bl_18m</th>\n",
       "      <th>hba1c_bl_6m</th>\n",
       "      <th>sp</th>\n",
       "      <th>ika</th>\n",
       "      <th>t2d_dur_y</th>\n",
       "      <th>P_Krea</th>\n",
       "      <th>...</th>\n",
       "      <th>date_bmi_12m</th>\n",
       "      <th>date_hdl_12m</th>\n",
       "      <th>days_hba1c</th>\n",
       "      <th>days_bmi</th>\n",
       "      <th>days_hdl</th>\n",
       "      <th>days_ldl</th>\n",
       "      <th>hba1c_12m</th>\n",
       "      <th>ldl_12m</th>\n",
       "      <th>hdl_12m</th>\n",
       "      <th>bmi_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8087</th>\n",
       "      <td>106358</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.7929</td>\n",
       "      <td>50.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>64542</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.2301</td>\n",
       "      <td>58.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>84221</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.2301</td>\n",
       "      <td>60.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>13</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>313.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.47</td>\n",
       "      <td>35.154137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6963</th>\n",
       "      <td>91189</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.7929</td>\n",
       "      <td>51.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>1043704</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.7929</td>\n",
       "      <td>46.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-07-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.654320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>91628</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.5743</td>\n",
       "      <td>65.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>385.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.45</td>\n",
       "      <td>31.673470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>58508</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.7929</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>69736</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.2301</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-11-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>384.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>384.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.488628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>1001933</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.7929</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>471.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13427</th>\n",
       "      <td>202173</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>-8.8533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.787994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2331 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  init_year  drug_class  MD_RCT_mmol_mol  hba1c_bl_18m  \\\n",
       "8087    106358       2018           3          -5.7929          50.0   \n",
       "4868     64542       2019           4          -6.2301          58.0   \n",
       "6448     84221       2019           4          -6.2301          60.0   \n",
       "6963     91189       2013           3          -5.7929          51.0   \n",
       "13607  1043704       2019           3          -5.7929          46.0   \n",
       "...        ...        ...         ...              ...           ...   \n",
       "7001     91628       2016           4          -5.5743          65.0   \n",
       "4446     58508       2018           3          -5.7929          56.0   \n",
       "5306     69736       2020           4          -6.2301          54.0   \n",
       "13507  1001933       2014           3          -5.7929          59.0   \n",
       "13427   202173       2017           4          -8.8533           NaN   \n",
       "\n",
       "       hba1c_bl_6m  sp   ika  t2d_dur_y  P_Krea  ...  date_bmi_12m  \\\n",
       "8087          55.0   1  83.0          4    56.0  ...           NaN   \n",
       "4868          68.0   2  76.0         17    85.0  ...           NaN   \n",
       "6448          58.0   1  56.0         13    62.0  ...    2020-11-05   \n",
       "6963          53.0   2  64.0          3    70.0  ...    2014-01-21   \n",
       "13607         59.0   2  60.0          6    94.0  ...    2019-07-09   \n",
       "...            ...  ..   ...        ...     ...  ...           ...   \n",
       "7001          74.0   2  70.0          7    58.0  ...    2017-02-07   \n",
       "4446          55.0   1  88.0          1    65.0  ...           NaN   \n",
       "5306          54.0   2  59.0          6    65.0  ...    2021-11-17   \n",
       "13507          NaN   2  51.0          3    57.0  ...           NaN   \n",
       "13427         55.0   2  64.0          0   114.0  ...    2017-06-15   \n",
       "\n",
       "       date_hdl_12m  days_hba1c  days_bmi  days_hdl  days_ldl  hba1c_12m  \\\n",
       "8087     2019-10-23       380.0       NaN     380.0     380.0       50.0   \n",
       "4868            NaN       274.0       NaN       NaN     274.0       49.0   \n",
       "6448     2020-04-07       313.0     357.0     229.0     313.0       59.0   \n",
       "6963            NaN       364.0     425.0       NaN       NaN       59.0   \n",
       "13607           NaN       350.0     343.0       NaN     350.0       49.0   \n",
       "...             ...         ...       ...       ...       ...        ...   \n",
       "7001     2017-04-04       385.0     307.0     385.0     385.0       65.0   \n",
       "4446            NaN       160.0       NaN       NaN       NaN       52.0   \n",
       "5306            NaN       384.0     355.0       NaN     384.0       56.0   \n",
       "13507           NaN         NaN       NaN       NaN     471.0       59.0   \n",
       "13427           NaN       345.0      94.0       NaN     345.0       65.0   \n",
       "\n",
       "       ldl_12m  hdl_12m    bmi_12m  \n",
       "8087       2.2     1.06        NaN  \n",
       "4868       2.9      NaN        NaN  \n",
       "6448       1.7     1.47  35.154137  \n",
       "6963       NaN      NaN  28.730000  \n",
       "13607      2.0      NaN  37.654320  \n",
       "...        ...      ...        ...  \n",
       "7001       2.4     1.45  31.673470  \n",
       "4446       NaN      NaN        NaN  \n",
       "5306       1.9      NaN  32.488628  \n",
       "13507      3.3      NaN        NaN  \n",
       "13427      2.6      NaN  32.787994  \n",
       "\n",
       "[2331 rows x 125 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "089d26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([df_original, df_missing_val_original])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abc4ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('../data/mvhba1c.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a11958f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hba1c_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8087</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6963</th>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7848</th>\n",
       "      <td>56.294547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>65.749411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>52.081039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>66.333191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>57.573497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2660 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hba1c_12m\n",
       "8087   50.000000\n",
       "4868   49.000000\n",
       "6448   59.000000\n",
       "6963   59.000000\n",
       "13607  49.000000\n",
       "...          ...\n",
       "7848   56.294547\n",
       "6216   65.749411\n",
       "8133   52.081039\n",
       "6160   66.333191\n",
       "279    57.573497\n",
       "\n",
       "[2660 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[['hba1c_12m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13962e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de294dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07b747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
